# ğŸ“Š Customer Churn Analytics Dashboard

This repository implements an **end-to-end analytics pipeline and executive dashboard** for analyzing customer churn for a subscription-based telecom service. It uses the public **Telco Customer Churn** dataset as a case study. The stack is **SQL â†’ R â†’ Tableau**: raw data is modeled and cleaned in SQL, transformed and aggregated in R, and visualized in a business-friendly Tableau dashboard to identify churn patterns, high-risk customer segments, and revenue at risk.

---

## ğŸ¯ Project Overview

The goal of this project is to:
- Build a **reproducible analytics pipeline** from raw Telco churn data to dashboard-ready outputs.
- **Identify churn patterns** and high-risk customer segments (e.g. by contract type, tenure, services).
- Quantify **revenue at risk** (MRR from churned or at-risk customers) to support retention decisions.
- Deliver an **executive-facing Tableau dashboard** with clear KPIs and actionable insights.

The pipeline cleanly separates **ingest (SQL)**, **transform (R)**, and **visualize (Tableau)** for maintainability and reuse.

---

## âœ¨ Key Features

- **SQL layer** (`sql/`): Create staging tables, clean and normalize data, and define KPI views for churn rate and revenue at risk.
- **R layer** (`r/`): Extract data from the database, build KPI and driver tables, and export CSVs for Tableau.
- **Tableau dashboard**: Connect to processed CSVs for churn rate, segment breakdowns, and revenue-at-risk visualizations.
- **Structured repository**: Clear separation of raw data, processed outputs, code, and documentation.
- **R dependency file** (`r/requirements.R`) for easy setup of DBI, dplyr, and related packages.

---

## ğŸ§± Repository Structure

```
customer-churn-dashboard/
â”‚
â”œâ”€â”€ data/                                  # Dataset storage (raw tracked in Git for GitHub Pages)
â”‚   â”œâ”€â”€ raw/                               # Unmodified input data (as downloaded)
â”‚   â”‚   â””â”€â”€ telco-churn.csv                # Telco Customer Churn source file (Kaggle)
â”‚   â””â”€â”€ processed/                         # Cleaned / aggregated CSVs exported for Tableau (generated by R; gitignored)
â”‚
â”œâ”€â”€ sql/                                   # Schema, staging, and KPI views for the analytics database
â”‚   â”œâ”€â”€ 01_create_tables.sql               # Create staging table(s) for raw churn data
â”‚   â”œâ”€â”€ 02_clean_staging.sql               # Clean, normalize, and build base table(s)
â”‚   â””â”€â”€ 03_kpi_views.sql                   # KPI views (churn rate, revenue at risk, segment breakdowns)
â”‚
â”œâ”€â”€ r/                                     # Extract from SQL, build KPI tables, churn driver analysis
â”‚   â”œâ”€â”€ 01_extract_from_sql.R              # Connect to DB and load staging / base tables into R
â”‚   â”œâ”€â”€ 02_kpi_tables.R                    # Build KPI aggregates and export to data/processed/
â”‚   â”œâ”€â”€ 03_churn_drivers.R                 # Churn driver analysis and segment exports for Tableau
â”‚   â””â”€â”€ requirements.R                     # R package dependencies (DBI, RSQLite, dplyr, etc.)
â”‚
â”œâ”€â”€ tableau/                               # Tableau workbook (dashboard.twbx or .twb); data source: data/processed/
â”œâ”€â”€ notebooks/                             # Jupyter / R Markdown notebooks for exploration and analysis
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ report.md                              # Technical report (methodology, pipeline, reproducibility)
```

> ğŸ—’ï¸ **Note:**  
> - **Raw data** in `data/raw/` **is tracked by Git** so the dataset can be used on GitHub Pages; it is *not* in `.gitignore`.  
> - **Processed data** in `data/processed/` is generated by the R scripts and is gitignored; only the folder structure is kept via `.gitkeep`.

---

## ğŸ§° Run Locally

### 1ï¸âƒ£ Clone the repository

**HTTPS (recommended for most users):**
```bash
git clone https://github.com/florykhan/customer-churn-dashboard.git
cd customer-churn-dashboard
```

**SSH (for users who have SSH keys configured):**
```bash
git clone git@github.com:florykhan/customer-churn-dashboard.git
cd customer-churn-dashboard
```

### 2ï¸âƒ£ Add the raw dataset

The **Telco Customer Churn** dataset is in `data/raw/telco-churn.csv`. If you need to re-download it, place the CSV there (same path).

> ğŸ“¥ **Download the dataset:** [Kaggle â€“ Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

### 3ï¸âƒ£ Run the SQL pipeline

Execute in order in your SQL engine (e.g. SQLite, Postgres):

1. `sql/01_create_tables.sql` â€” create schema and staging table(s)  
2. `sql/02_clean_staging.sql` â€” clean and create base table(s)  
3. `sql/03_kpi_views.sql` â€” create KPI views  

(Adjust table names and paths in the scripts to match your environment and CSV layout.)

### 4ï¸âƒ£ Install R dependencies and run the R pipeline

In R:

```r
source("r/requirements.R")   # Install DBI, RSQLite, dplyr, etc.
# Then run in order:
# 01_extract_from_sql.R  â†’ connect to DB, load tables
# 02_kpi_tables.R        â†’ build KPI tables, write to data/processed/
# 03_churn_drivers.R     â†’ churn drivers, write to data/processed/
```

### 5ï¸âƒ£ Build the Tableau dashboard

- Connect Tableau to the CSVs in `data/processed/`.
- Create views for churn rate, segments, and revenue at risk.
- Save the workbook as `tableau/dashboard.twbx` (or add a `.twb`).

---

## ğŸ“Š Results (Summary)

| **Deliverable** | **Description** |
|-----------------|------------------|
| Churn rate & trend | Overall and time/segment-level churn metrics |
| High-risk segments | e.g. Month-to-month, low tenure, specific service combinations |
| Revenue at risk | MRR from churned (and optionally at-risk) customers |
| Executive dashboard | Tableau workbook for stakeholders |

â¡ï¸ For pipeline details, metrics definitions, and reproducibility steps, see the full report: [`report.md`](report.md).

---

## ğŸ“„ Full Technical Report

For the complete methodology, pipeline overview, and reproducibility instructions, see: [`report.md`](report.md). That document is intended for reviewers and anyone who wants to understand the full SQL â†’ R â†’ Tableau workflow and metrics.

---

## ğŸš€ Future Directions

- **Predictive churn model:** Add an R or Python step to train a churn propensity model and export scores for Tableau.
- **Automation:** Schedule SQL and R runs (e.g. cron, GitHub Actions) and refresh Tableau extracts.
- **Additional segments:** Drill into tenure bands, product bundles, and demographic splits.
- **Alerts:** Integrate thresholds (e.g. segment churn rate > X%) with notifications or a simple API.

---

## ğŸ§  Tech Stack

- **Data:** Telco Customer Churn ([Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn))  
- **SQL:** Schema, staging, cleaning, KPI views (SQLite / Postgres compatible)  
- **R:** DBI, RSQLite, dplyr, tidyr, readr â€” extract, transform, export to CSV  
- **Tableau:** Dashboard on processed CSVs  
- **Version control:** Git + GitHub (raw data tracked for GH Pages)

---

## ğŸ§¾ License

MIT License, feel free to use and modify with attribution. See the [`LICENSE`](./LICENSE) file for full details.

---

## ğŸ‘¤ Author

**Ilian Khankhalaev**  
_BSc Computing Science, Simon Fraser University_  
ğŸ“ Vancouver, BC  |  [florykhan@gmail.com](mailto:florykhan@gmail.com)  |  [GitHub](https://github.com/florykhan)  |  [LinkedIn](https://www.linkedin.com/in/ilian-khankhalaev/)
